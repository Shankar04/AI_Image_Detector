# -*- coding: utf-8 -*-
"""FIRE_ASN_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T3-dAXH9rwcA0ZQKErDSztaehOeSV2YW
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
#Complete the path below to go to the folder that contains the code
# Allows us to connect to google drive an retrieve data from there
# %cd /content/gdrive/'MyDrive/Colab Notebooks/Data/'
# %ls

#retrives file name in google doc and reads data from top
!head -10 REGRESSION-gradientDescent-data.txt
#prints to console
!echo ""============================""
# reads data from bottom
!tail -10 REGRESSION-gradientDescent-data.txt


#importing python library called future, which is a built-in module in Python that is used to inherit new features that will be available in the new Python versions.
# We want the print_function which allows to to write the print() function in the syntax of Python 3 while we are not on that version
from __future__ import print_function

#importing numpy module which is a package with high-level mathematical functions
import numpy as np

#imports python module matplotlib.pyplot is a state-based interface to matplotlib.
#It provides an implicit, MATLAB-like, way of plotting. It also opens figures on your screen, and acts as the figure GUI manager.
import matplotlib.pyplot as plt
import matplotlib


#rcParams is a dictionary of most matplotlib styling that you set at the start of your notebook and it will apply to all your plots.
matplotlib.rcParams['mathtext.fontset'] = 'stix'
matplotlib.rcParams['font.family'] = 'STIXGeneral'
matplotlib.rcParams.update({'font.size': 18})
plt.rcParams.update({'font.size': 22})



#creating a function to plot original data
def plot_original_data():
    #no.loadtxt() allows you to load data from a txt file
    #fname is the file name, delimiter is what the function uses to identify how to spearate the data,
    #the unpack = True allows you to transpose the returned array, so that arrays are returned for each field, x and y.
    #skiprows will skip the first skiprows lines (1 in this case); and the usecols = (2, 4) means tells which columns to read, with 0 being the first.
    #In this case, it will extract the 2 and 4 columns
    #set x and y to the values in the given columns, radio and sales
    x, y = np.loadtxt(fname, delimiter= ",", unpack = True,skiprows=1,usecols=(2,4))


    #plot all the points x,y gathered from previous line as scatterplot
    plt.scatter(x, y, color='#76EEC6', marker='o')

    #sets x axis label to spendings
    plt.xlabel("Spendings")
    #plt.ylabel("Sales, Units")
    #plt.title("Sales as a function of radio ad spendings.")
    #labels for the graph

    #gcf() is primarily used to get the current figure. If no current figure is available then one is created with the help of the figure() function
    fig1 = plt.gcf()

    #Adjust the subplot layout parameters, where top and bottom are the positions of the top/bottom edge of the subplots, as a fraction of the figure height
    # wspace is the width of the padding between subplots, as a fraction of the average Axes width
    #hspace is the height of the padding between subplots, as a fraction of the average Axes height
    fig1.subplots_adjust(top = 0.98, bottom = 0.1, right = 0.98, left = 0.08, hspace = 0, wspace = 0)


#creating a new function called update_w_and_b which is used in the values for the gradient descent
def update_w_and_b(spendings, sales, w, b, alpha):
    #sets variables to 0.0 float point numbers
    dr_dw = 0.0
    dr_db = 0.0

    #len() returns the number of items in the container passed in by the parameter spendings
    N = len(spendings)

    #for loop to differentiate the function with respect to the cost function using the values of weights and biased.
    #We are following the slope in a certain direction and reaching at some point we update the values of the weight and biased.
    for i in range(N):
        dr_dw += -2 * spendings[i] * (sales[i] - (w * spendings[i] + b))
        dr_db += -2 * (sales[i] - (w * spendings[i] + b))

    # update w and b

    #We use the gradient descent weight algorith which is w = w - a*(partial derivative of the loss which we calculated in the variable dr_dw)/(partial derivative of w)
    w = w - (dr_dw/float(N)) * alpha
    b = b - (dr_db/float(N)) * alpha

    return w, b


#function used to train the gradient descent function with the weights and bias from above function
def train(spendings, sales, w, b, alpha, epochs):

    image_counter = 2;

     #Create a new figure, or activate an existing figure. If a figure with 1 already exists, this figure is made active and returned
    plt.figure(1)

    #loops thorugh sequence the number of times epoch is set to in order to keep updating and traning the values.
    for e in range(epochs):

        #calls the previos function to keep updating the weights and biases every epoch that is passed
        w, b = update_w_and_b(spendings, sales, w, b, alpha)

        # The entire if statment is used to determine which epoch to print steps. Rather than prining out every epoch, it will print out every 200
        # epochs until it gets to 3000, from which it will start printing out every 3000 epochs.
        if (e == 0) or (e < 3000 and e % 200 == 0) or (e % 3000 == 0):

            #printing values
            print("epoch: ", str(e), "loss: "+str(loss(spendings, sales, w, b)))
            print("w, b: ", w, b)
            #plt.figure(image_counter)

            #setting how plot should look like in regards to axises, labels, etc.
            axes = plt.gca()
            axes.set_xlim([0,50])
            axes.set_ylim([0,30])
            plt.scatter(spendings, sales)
            #plt.xlabel("Spendings, M$")
            #plt.ylabel("Sales, Units")
            plt.ylabel("Sales")
            #plt.title("Epoch "+str(e))

            # uses the linspace() method to return evenly spaced numbers over a specified interval.
            # Returns num evenly spaced samples, calculated over the interval [start, stop].
            X_plot = np.linspace(0,50,50)

            #plots y versus x as lines and/or markers
            plt.plot(X_plot, X_plot*w + b)
            #plt.show()

            #.gcf() gets current figure
            fig1 = plt.gcf()

            #Adjust the subplot layout parameters, where top and bottom are the positions of the top/bottom edge of the subplots
            fig1.subplots_adjust(top = 0.98, bottom = 0.1, right = 0.98, left = 0.08, hspace = 0, wspace = 0)

            image_counter += 1
    return w, b


#function used to calculate the loss for each gradient. We want to minimize this value in order to find the best line that minimizes the distance between all the points
def loss(spendings, sales, w, b):
    #sets N to the number of contents in the spendings array
    N = len(spendings)

    #set current error to 0
    total_error = 0.0
    for i in range(N):
        #Uses the MSE formula to calculate the error and add it to the total error is among all the points
        total_error += (sales[i] - (w*spendings[i] + b))**2
    #returns average error for that set of data
    return total_error / N

#function used to predict using a learning model of weight * input + bias
def predict(x, w, b):
    return w*x + b


#input file named
fname="REGRESSION-gradientDescent-data.txt"

#calculate the loss which will be used in the weights and bias to improve accuracy
x, y = np.loadtxt(fname, delimiter= ",", unpack = True,skiprows=1,usecols=(2,4))
w, b = train(x, y, 0.0, 0.0, 0.0001, 10000)

plot_original_data()